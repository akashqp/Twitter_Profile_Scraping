{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55914ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary librarires\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9333c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_profile(url):\n",
    "    # Set up Selenium Options\n",
    "    options = Options()\n",
    "    options.headless = True # Run the Browser in headless mode\n",
    "\n",
    "    # Set up the Selenium Chrome Driver\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    # Open the Twitter Profile url\n",
    "    driver.get(url)\n",
    "    time.sleep(2) # Wait for the page to load\n",
    "\n",
    "    # Extract the required details\n",
    "    try:\n",
    "        username = driver.find_element(By.XPATH, \"//div[@data-testid='UserName']\")\n",
    "    except NoSuchElementException:\n",
    "        username = None\n",
    "    try:\n",
    "        bio = driver.find_element(By.XPATH, \"//div[@data-testid='UserDescription']\")\n",
    "    except NoSuchElementException:\n",
    "        bio = None\n",
    "    try:\n",
    "        following_count = driver.find_element(By.XPATH, \"//a[contains(@href,'/following')]//span[1]\")\n",
    "    except NoSuchElementException:\n",
    "        following_count = None\n",
    "    try:\n",
    "        followers_count = driver.find_element(By.XPATH, \"//a[contains(@href,'/followers')]//span[1]\")\n",
    "    except NoSuchElementException:\n",
    "        followers_count = None\n",
    "    try:\n",
    "        location = driver.find_element(By.XPATH, \"//span[@data-testid='UserLocation']\")\n",
    "    except NoSuchElementException:\n",
    "        location = None\n",
    "    try:\n",
    "        website = driver.find_element(By.XPATH, \"//a[@data-testid='UserUrl']\")\n",
    "    except NoSuchElementException:\n",
    "        website = None\n",
    "    \n",
    "    # Appending the Scrapped values to List\n",
    "    usernames.append(username.text if username else 'N/A')\n",
    "    bios.append(bio.text if bio else 'N/A')\n",
    "    following_counts.append(following_count.text if following_count else 'N/A')\n",
    "    followers_counts.append(followers_count.text if followers_count else 'N/A')\n",
    "    locations.append(location.text if location else 'N/A')\n",
    "    websites.append(website.text if website else 'N/A')\n",
    "    \n",
    "    # Close the Selenium Chrome Driver\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e83e4693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_15364\\53516454.py:4: DeprecationWarning: headless property is deprecated, instead use add_argument('--headless') or add_argument('--headless=new')\n",
      "  options.headless = True # Run the Browser in headless mode\n",
      "[WDM] - Downloading: 100%|████████████████████████████████████████████████████████| 6.30M/6.30M [00:04<00:00, 1.45MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Reading the Twitter URLs from a CSV file:\n",
    "df = pd.read_csv('twitter_links.csv', header=None)\n",
    "twitter_urls = df[0]\n",
    "\n",
    "# Initialize lists to store the scraped data\n",
    "usernames = []\n",
    "bios = []\n",
    "followers_counts = []\n",
    "following_counts = []\n",
    "locations = []\n",
    "websites = []\n",
    "\n",
    "# Scraping the profiles\n",
    "for url in twitter_urls:\n",
    "    scrape_profile(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a017275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary from the scraped data\n",
    "data = {\n",
    "    'Bio': bios,\n",
    "    'Following Count': following_counts,\n",
    "    'Followers Count': followers_counts,\n",
    "    'Location': locations,\n",
    "    'Websites': websites\n",
    "}\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the dataframe to a csv file\n",
    "df.to_csv('twitter_profiles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29c50fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating another csv file with username in it to facilitate viewing\n",
    "# Create a dictionary from the scraped data\n",
    "data = {\n",
    "    'Username': usernames,\n",
    "    'Bio': bios,\n",
    "    'Following Count': following_counts,\n",
    "    'Followers Count': followers_counts,\n",
    "    'Location': locations,\n",
    "    'Websites': websites\n",
    "}\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the dataframe to a csv file\n",
    "df.to_csv('modified_twitter_profiles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5360e545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Username': ['GTN UK\\n@GTNUK1',\n",
       "  'WhatsApp\\n@WhatsApp',\n",
       "  'A & A Customs Broker\\n@aacb_CBPTrade',\n",
       "  'A&A Customs Brokers\\n@aacbdotcom',\n",
       "  'A&A Window Products\\n@AAWindowPRODUCT',\n",
       "  'A & B Kia\\n@AandB_Kia',\n",
       "  'A&B Home\\n@ABHomeInc',\n",
       "  'A & B Reprographics\\n@Abrepro',\n",
       "  'N/A',\n",
       "  'A & C CHRISTOFI LTD\\n@ACChristofiLtd',\n",
       "  'A&E Clothing\\n@aeclothing1',\n",
       "  'N/A',\n",
       "  'A & E Technologies\\n@AETechnologies1',\n",
       "  'Wix\\n@Wix',\n",
       "  'A & G Insurance LLC\\n@AGInsuranceLLC'],\n",
       " 'Bio': ['Providing Entertainment & Travel to Commercial Radio. Reaching 28.9M weekly listeners. Winners of The Arqiva National Sales Team of the Year 2010, 2011 & 2016',\n",
       "  'Happy #PrideMonth \\n#CrossingCultures Ep 2, out now ',\n",
       "  'Customs Broker',\n",
       "  'A & A Freight | Warehousing | Customs Brokerage | Helping people ship across borders.',\n",
       "  'A commercial glass and glazing company serving the window industry in New England since 1954. #SafetyQualityService',\n",
       "  'A&B Kia is a Kia dealer in Benwood, WV. Stay connected to exceed expectations. Build strong relationships. Drive the best with us.',\n",
       "  'Industry leader in wholesale home decor, furniture, and garden, since 1993.',\n",
       "  'From large format black & white prints to the most sophisticated of digital color printing jobs, A & B can get the job done right.',\n",
       "  'N/A',\n",
       "  'A & C CHRISTOFI LTD is a fast growing professional services company based in Limassol, Cyprus. Our main Concern is your Business.',\n",
       "  'Used Clothing Distributor',\n",
       "  'N/A',\n",
       "  'N/A',\n",
       "  'Create, manage and grow your business online with Wix. It’s more than just a website builder, it’s how your vision comes to life. For support: \\n@WixHelp\\n.',\n",
       "  'A & G Insurance prides itself on being your local, full service, Independent Insurance Agency.'],\n",
       " 'Following Count': ['463',\n",
       "  '2',\n",
       "  '125',\n",
       "  '4,077',\n",
       "  '90',\n",
       "  '345',\n",
       "  '184',\n",
       "  '125',\n",
       "  'N/A',\n",
       "  '282',\n",
       "  '0',\n",
       "  'N/A',\n",
       "  '1',\n",
       "  '3,722',\n",
       "  '260'],\n",
       " 'Followers Count': ['126',\n",
       "  '4.8M',\n",
       "  '31',\n",
       "  '665',\n",
       "  '76',\n",
       "  '296',\n",
       "  '360',\n",
       "  '137',\n",
       "  'N/A',\n",
       "  '87',\n",
       "  '15',\n",
       "  'N/A',\n",
       "  '37',\n",
       "  '418.3K',\n",
       "  '40'],\n",
       " 'Location': ['London, England',\n",
       "  'California',\n",
       "  'Florida, USA',\n",
       "  'Worldwide',\n",
       "  'Malden, MA',\n",
       "  'Benwood, West Virginia ',\n",
       "  'Rancho Cucamonga, CA',\n",
       "  'Bentonville, AR',\n",
       "  'N/A',\n",
       "  'Cyprus',\n",
       "  'Carteret',\n",
       "  'N/A',\n",
       "  'Boulder, CO USA',\n",
       "  \"We're everywhere!\",\n",
       "  'Connecticut'],\n",
       " 'Websites': ['gtn.uk.com/index.php',\n",
       "  'bit.ly/3IRGfXH',\n",
       "  'N/A',\n",
       "  'aacb.com',\n",
       "  'aawindowproducts.com',\n",
       "  'aandbautosales.com',\n",
       "  'abhomeinc.com',\n",
       "  'abrepro.com',\n",
       "  'N/A',\n",
       "  'acccyp.com',\n",
       "  'aeclothing.net',\n",
       "  'N/A',\n",
       "  'ae-technologies.com',\n",
       "  'wix.com',\n",
       "  'aginsuranceinc.com']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0196d14e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
